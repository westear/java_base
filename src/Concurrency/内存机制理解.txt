url:http://blog.csdn.net/opensure/article/details/46669337
处理器为了提高处理速度，不直接和内存进行通讯，而是先将系统内存的数据读到内部缓存（L1,L2或其他）后再进行操作，但操作完之后不知道何时会写到内存；
如果对声明了Volatile变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。
但是就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题，所以在多处理器下，为了保证各个处理器的缓存是一致的，就会实现<缓存一致性协议>，
每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，
当处理器要对这个数据进行修改操作的时候，会强制重新从系统内存里把数据读到处理器缓存里.

缓存一致性机制:会阻止同时修改被两个以上处理器缓存的内存区域数据。一个处理器的缓存回写到内存会导致其他处理器的缓存无效.以此实现缓存一致性

Volatile的使用优化

著名的Java并发编程大师Doug lea在JDK7的并发包里新增一个队列集合类LinkedTransferQueue，他在使用Volatile变量时，
用一种追加字节的方式来优化队列出队和入队的性能。
追加字节能优化性能？这种方式看起来很神奇，但如果深入理解处理器架构就能理解其中的奥秘。让我们先来看看LinkedTransferQueue这个类，
它使用一个内部类类型来定义队列的头队列（Head）和尾节点（tail），而这个内部类PaddedAtomicReference相对于父类AtomicReference只做了一件事情，
就将共享变量追加到64字节。我们可以来计算下，一个对象的引用占4个字节，它追加了15个变量，共占60个字节，再加上父类的Value变量，一共64个字节。
代码如下：
	/**head of the queue */
    private transient final PaddedAtomicReference< QNode > head;
 
	/** tail of the queue */
    private transient final PaddedAtomicReference< QNode > tail;
 
 	static final class PaddedAtomicReference< T > extends AtomicReference< T > {
	 	//enough padding for 64bytes with 4byte refs 
	 	Object p0, p1, p2, p3, p4, p5, p6, p7, p8, p9, pa, pb, pc, pd, pe;
	 
	    PaddedAtomicReference(T r) { 
	            super(r);
	    }
 
	}
 
    public class AtomicReference< V > implements java.io.Serializable{
        private volatile V value;
    }

    
为什么追加64字节能够提高并发编程的效率呢？
 因为对于英特尔酷睿i7，酷睿， Atom和NetBurst， Core Solo和Pentium M处理器的L1，L2或L3缓存的高速缓存行是64个字节宽，不支持部分填充缓存行，
 这意味着如果队列的头节点和尾节点都不足64字节的话，处理器会将它们都读到同一个高速缓存行中，在多处理器下每个处理器都会缓存同样的头尾节点，
 当一个处理器试图修改头接点时会将整个缓存行锁定，那么在缓存一致性机制的作用下，会导致其他处理器不能访问自己高速缓存中的尾节点，
 而队列的入队和出队操作是需要不停修改头接点和尾节点，所以在多处理器的情况下将会严重影响到队列的入队和出队效率。
 Doug lea使用追加到64字节的方式来填满高速缓冲区的缓存行，避免头接点和尾节点加载到同一个缓存行，使得头尾节点在修改时不会互相锁定。

那么是不是在使用Volatile变量时都应该追加到64字节呢？
不是的。在两种场景下不应该使用这种方式。
第一：缓存行非64字节宽的处理器，如P6系列和奔腾处理器，它们的L1和L2高速缓存行是32个字节宽。
第二：共享变量不会被频繁的写。因为使用追加字节的方式需要处理器读取更多的字节到高速缓冲区，这本身就会带来一定的性能消耗，共享变量如果不被频繁写的话，锁的几率也非常小，
就没必要通过追加字节的方式来避免相互锁定。

Java并发编程实践写道：“一个理解volatile变量好的方法：想想它们的行为与SynchrosizedInteger类相似，只不过用get和set方法取代了对volatile变量的读写操作。
然而访问volatile变量的操作不会加锁，也就不会引起线程的阻塞，这使volatile相对于synchronized而言，只是轻量级的同步机制”。


伪共享：
 可见每个cpu核心或者线程都会可能往同一个缓存行写数据；并且对共享变量，同时cpu核心会有各自的缓存行
假设：多核CPU下，有共享变量x和y被放在同一个高速缓存行，如果一个线程修改x；那么另外一个线程修改y，必须等待x修改完成后才能实施。
虽然两个线程修改各种独立变量，但是因为这些独立变量被放在同一个高速缓存区，性能就影响了。
当多核CPU线程同时修改在同一个高速缓存行各自独立的变量时，会不自不觉地影响性能，这就发生了伪共享False sharing，伪共享是性能的无声杀手。

解决方法：是将高速缓存剩余的字节填充填满(pad)，确保不发生多个字段被挤入一个高速缓存区（一般来说64位处理器下最好将告诉缓冲行的64位字节填满）

